{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FTmZWUrN1iem",
        "outputId": "1133b806-191e-43d1-cb7a-00bcaeac5d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-upstage\n",
            "  Downloading langchain_upstage-0.1.5-py3-none-any.whl (14 kB)\n",
            "Collecting langchain-core<0.3,>=0.1.52 (from langchain-upstage)\n",
            "  Downloading langchain_core-0.2.0-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai<0.2.0,>=0.1.3 (from langchain-upstage)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.24.1 (from langchain-upstage)\n",
            "  Downloading PyMuPDF-1.24.4-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from langchain-upstage) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-upstage) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.1.52->langchain-upstage)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.3,>=0.1.52->langchain-upstage)\n",
            "  Downloading langsmith-0.1.60-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.3,>=0.1.52->langchain-upstage)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-upstage) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-upstage) (8.3.0)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.3 (from pymupdf<2.0.0,>=1.24.1->langchain-upstage)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2024.2.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-upstage)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain-upstage)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-upstage) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-upstage) (2.18.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (2023.12.25)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (1.2.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, packaging, orjson, jsonpointer, h11, tiktoken, pymupdf, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-openai, langchain-upstage\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed PyMuPDFb-1.24.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.2.0 langchain-openai-0.1.7 langchain-upstage-0.1.5 langsmith-0.1.60 openai-1.30.1 orjson-3.10.3 packaging-23.2 pymupdf-1.24.4 tiktoken-0.7.0\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.0 (from langchain-community)\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.60)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-text-splitters, langchain, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.6 faiss-cpu-1.8.0 langchain-0.2.0 langchain-community-0.2.0 langchain-text-splitters-0.2.0 marshmallow-3.21.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-upstage\n",
        "!pip install -U langchain-community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HmRghUMw4ltR"
      },
      "outputs": [],
      "source": [
        "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_upstage import ChatUpstage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_upstage import ChatUpstage\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c7rvXu6T4lxb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "files = [file for file in glob.glob(\"/content/pdf_datasets/*\")]\n",
        "def read_dataset(files):\n",
        "    all_docs = []\n",
        "    for file_name in files:\n",
        "        # Load the file\n",
        "        file1_load = UpstageLayoutAnalysisLoader(file_name, split=\"page\", api_key=\"UPSTAGE-API-KEY\")\n",
        "        docs = file1_load.load()\n",
        "        for doc in docs:\n",
        "            all_docs.append(doc)\n",
        "    return all_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZeRxm8_QXWG",
        "outputId": "894467be-1058-4373-af4f-b31860a0d6c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/pdf_datasets/paper2.pdf',\n",
              " '/content/pdf_datasets/paper1.pdf',\n",
              " '/content/pdf_datasets/Automatic_Gender_Detection.pdf',\n",
              " '/content/pdf_datasets/gender_b_social_media.pdf']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "w9n9qAOk6dDu"
      },
      "outputs": [],
      "source": [
        "from langchain_upstage import UpstageEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "embeddings = UpstageEmbeddings(\n",
        "  upstage_api_key=\"UPSTAGE-API-KEY\",\n",
        "  model=\"solar-embedding-1-large\"\n",
        ")\n",
        "# Embed and store all documents in FAISS\n",
        "docs = read_dataset(files)\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size = 500, chunk_overlap=0)\n",
        "docs_split = text_splitter.split_documents(docs)\n",
        "\n",
        "db = FAISS.from_documents(docs_split, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WWyQ4Y3H6dGB"
      },
      "outputs": [],
      "source": [
        "# Asking the retriever to do similarity search based on Query\n",
        "#query = \"Tell me about gender bias. Use the embedded documents as context\"\n",
        "# answer = db.similarity_search(query)\n",
        "\n",
        "# Building the retriever\n",
        "retriever = db.as_retriever()#search_kwargs = {'k': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bw_37VQ3W9uZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "template = \"\"\"\n",
        "\n",
        "  You are a pdf file information retrieval AI chat assistant. Format the retrieved information as text.\n",
        "\n",
        "\n",
        "  Use only the context for your answers, do not make up information.\n",
        "\n",
        "  query: {query}\n",
        "\n",
        "  {context}\n",
        "\"\"\"\n",
        "# using chain\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatUpstage()\n",
        "chain = (\n",
        "    {\n",
        "        \"context\" : retriever,\n",
        "        \"query\" : RunnablePassthrough()\n",
        "    }\n",
        "    | prompt | model | StrOutputParser()\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "edJtpZ57W9zv",
        "outputId": "8c4f71f0-edb0-46a1-ba98-34f22d18b3e9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Stereotypical beliefs about women can vary widely depending on the culture and context. However, some common stereotypes include:\\n\\n1. Women are more emotional and less rational than men.\\n2. Women are more nurturing and caring than men.\\n3. Women are more passive and submissive than men.\\n4. Women are more focused on relationships and less focused on career than men.\\n5. Women are more likely to be victims of crime or abuse than men.\\n6. Women are less capable in certain fields, such as science, technology, engineering, and mathematics (STEM).\\n\\nIt is important to note that these stereotypes are not true for all women and can be harmful and limiting. It is also important to recognize and challenge these stereotypes in order to promote gender equality and empower women.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"\"\" What are stereotypical beliefs about women? Use all the embedded documents for context.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "CIBzQdmNW91P",
        "outputId": "55ee0216-5c87-4d91-a3a1-3a911b50f8be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Gender bias refers to an unfair difference in the way women and men are treated. It has a long history dating back to ancient times, with stereotypes and beliefs that have dominated our minds. Women were often seen as inferior to men due to the belief that they were intellectually and physically inferior. This belief was fueled by the fact that men often fought in wars and competed for women, leading to the idea that males were \"more evolved\" than women. These ideas have been passed down through generations, creating the stereotypes we have today.\\n\\nGender bias can have harmful impacts in real life and can also subconsciously dictate biased viewpoints for large online groups, causing them to further weaponize the bias and spread it. Artificial Intelligence (AI) can potentially mitigate the risk of biases in digital content, as AI algorithms do not have the unconscious assumptions from humans, resulting in less discrimination. However, there is a dilemma as AI can also introduce bias if not used cautiously. Machine learning models are trained on data, which can cause the fairness of the models to be influenced by the data. When training data disproportionately represents certain groups or has flawed information reflecting historical inequalities, algorithmic bias can appear. Furthermore, the people behind an AI solution can also cause bias, as women are under-represented in the AI professional community.\\n\\nThere has been prior research done on the topic of AI solving gender bias, such as reducing gender bias in news articles and detecting hate speech, including gender biased content. Our research aims to provide a solution using AI to detect gender bias in digital content by sorting every relevant word whether it is a stronger female indicator or a stronger male indicator. We utilize Word2Vec, focus on contextual content, and use user-generated content in the top-ranked bias categories.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"\"\" What can you tell me about gender bias? Use all the embedded documents for context.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "dnL9yzx3CWxY",
        "outputId": "55ecd9a0-a6f9-4c67-9211-411068a88330"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The representation of women in STEM fields is a complex issue that has been the subject of much research and debate. The underrepresentation of women in STEM careers is often referred to as a \"leaky pipeline,\" which describes the gender imbalance that is believed to be affected by a combination of institutional and cultural factors. These factors include biological differences between men and women, girls\\' lack of academic preparation for a science major/career, poor attitudes toward science, the absence of female scientists/engineers as role models, and cultural pressures on girls/women to conform to traditional gender roles.\\n\\nDespite these challenges, there are efforts to alleviate the underrepresentation of women in STEM fields, including diversity campaigns and sponsoring girls and women to attend courses and conferences. Proposed holistic solutions in the literature include increasing the appointment of women in powerful positions, redefining success in academia, and addressing the institutional and cultural factors that contribute to the underrepresentation of women in STEM fields.\\n\\nSocial media platforms, such as Twitter, have also emerged as a supportive platform for women working in STEM fields. Twitter users employ hashtags such as #ilooklikeasurgeon and #womeninSTEM to promote the work of women in STEM fields, show their appreciation of women working and studying in STEM, and challenge prevalent gender stereotypes of STEM professions. The discourse of women in STEM in social media is an example of discursive activism that focuses on the larger dialogue of women in STEM and highlights dominant forms of sexism and gendered stereotypes of women\\'s work in male-dominated professions.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"\"\" How is women's representation in STEM? Use all the embedded documents for context.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0whmgwf497z"
      },
      "source": [
        "References:\n",
        "1. https://python.langchain.com/v0.1/docs/integrations/document_loaders/upstage/\n",
        "2. https://medium.com/firebird-technologies/chat-with-your-pdfs-using-langchain-e57866b7926d"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
